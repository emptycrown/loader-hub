{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2b2eba-b7fd-4856-960f-f2cbadcc12af",
   "metadata": {},
   "source": [
    "# Building a Exa (formerly Metaphor) Data Agent\n",
    "\n",
    "This tutorial walks through using the LLM tools provided by the [Exa API](https://exa.ai) to allow LLMs to easily search and retrieve HTML content from the Internet.\n",
    "\n",
    "To get started, you will need an [OpenAI api key](https://platform.openai.com/account/api-keys) and an [Exa API key](https://dashboard.exa.ai/overview)\n",
    "\n",
    "We will import the relevant agents and tools and pass them our keys here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2a0ecd-22e9-4cef-b069-89e4286e4d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "retrieve_documents\n",
      "search_and_retrieve_documents\n",
      "search_and_retrieve_highlights\n",
      "find_similar\n",
      "current_date\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI\n",
    "import os\n",
    "import openai\n",
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set up Metaphor tool\n",
    "from llama_hub.tools.exa.base import ExaToolSpec\n",
    "\n",
    "exa_tool = ExaToolSpec(\n",
    "    api_key=os.environ[\"EXA_API_KEY\"],\n",
    ")\n",
    "\n",
    "exa_tool_list = exa_tool.to_tool_list()\n",
    "for tool in exa_tool_list:\n",
    "    print(tool.metadata.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e3012-bab0-4e55-858a-e3721282552c",
   "metadata": {},
   "source": [
    "## Testing the Exa tools\n",
    "\n",
    "We've imported our OpenAI agent, set up the api key, and initialized our tool, checking the methods that it has available. Let's test out the tool before setting up our Agent.\n",
    "\n",
    "All of the Exa search tools make use of the `AutoPrompt` option where Exa will pass the query through an LLM to refine and improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64da618-b4ab-42d7-903d-f4eeb624f43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exa Tool] Autoprompt: Here is a great article about machine learning transformers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id_='d9291e44-f359-466d-ae3b-20e2cdac90ea', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The famous paper “Attention is all you need” in 2017 changed the way we were thinking about attention. With enough data, matrix multiplications, linear layers, and layer normalization we can perform state-of-the-art-machine-translation.Nonetheless, 2020 was definitely the year of transformers! From natural language now they are into computer vision tasks. How did we go from attention to self-attention? Why does the transformer work so damn well? What are the critical components for its success?R', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='8e140d86-adab-4665-af6d-93d2f2ce7743', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n December 18, 2021\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n 7 minute read\\n \\n \\n \\n \\n \\n \\n \\n \\n \\nSummary\\nTransformers architectures are the hottest thing in supervised and unsupervised learning, achieving SOTA results on natural language processing, vision, audio and multimodal tasks. Their key capability is to capture which elements in a long sequence are worthy of attention, resulting in great summarisation and generative skills. Can we transfer any of these skills to reinforcement learning? The ans', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='835eafc8-fd53-463b-86af-c4d088e4c51d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Hands-on TutorialsThis article aims to introduce/refresh the main ideas behind Transformers and to present the latest advancements on using these models for Computer Vision applications.After reading this article you will know…… why Transformers outperformed SOTA models in NLP tasks.… how the Transformer model works at a glance.… which are the main limitations of convolutional models.… how Transformers can overcome limitations in convolutional models.… how novel works use Transformers for Comput', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exa_tool.search_and_retrieve_documents(\"machine learning transformers\", num_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55a0c7b-4c58-4725-8543-29bb1b7278ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'A Deep Dive Into the Transformer Architecture — The Development of Transformer Models',\n",
       "  'url': 'https://towardsdatascience.com/a-deep-dive-into-the-transformer-architecture-the-development-of-transformer-models-acbdf7ca34e0?gi=b4d77d2ab4db',\n",
       "  'id': '60J3eIu_oZO9OEulMglxuw'},\n",
       " {'title': 'What is a Transformer?',\n",
       "  'url': 'https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04',\n",
       "  'id': 'uxGX5rLD8HXrmgQiyQIYyw'},\n",
       " {'title': 'The Transformer Model',\n",
       "  'url': 'https://towardsdatascience.com/attention-is-all-you-need-e498378552f9?gi=92758857966b',\n",
       "  'id': 'RKL4_dd9kKX_OThZCXo8Yg'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exa_tool.find_similar(\n",
    "    \"https://www.mihaileric.com/posts/transformers-attention-in-disguise/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc8665d-ddb8-411f-b187-93a132d19e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exa Tool] Autoprompt: Here is a great explanation for machine learning transformers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id_='3a0f92c4-acfe-4198-8727-ed8f9b6ba5a2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\n \\n \\n \\n Background: Representation Learning for NLP\\n Enter the Transformer\\n Transformers vs. CNNs \\n Language\\n Vision\\n Multimodal Tasks\\n \\n \\n Breaking down the Transformer \\n Background \\n One-hot encoding \\n Overview\\n Idea\\n Example: Basic Dataset\\n Example: NLP\\n \\n \\n Dot product \\n Algebraic Definition\\n Geometric Definition\\n Properties of the dot product\\n \\n \\n Matrix multiplication as a series of dot products \\n Matrix multiplication as a table lookup\\n \\n \\n First order sequence model\\n Second order sequenc', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exa_tool.search_and_retrieve_documents(\n",
    "    \"This is the best explanation for machine learning transformers:\", num_results=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210906d-87a7-466a-9712-1d17dba2c2ec",
   "metadata": {},
   "source": [
    "We can see we have different tools to search for results, retrieve the results, find similar results to a web page, and finally a tool that combines search and document retrieval into a single tool. We will test them out in LLM Agents below:\n",
    "\n",
    "### Using the Search and Retrieve documents tools in an Agent\n",
    "\n",
    "We can create an agent with access to the above tools and start testing it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d88c2ee-184a-4371-995b-a086b34db24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't give the Agent our unwrapped retrieve document tools, instead passing the wrapped tools\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    exa_tool_list,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69a53fd-55c4-4e18-8fbe-6a29d5f3cef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What are the best resturants in toronto?\n",
      "=== Calling Function ===\n",
      "Calling function: search with args: {\n",
      "  \"query\": \"best restaurants in Toronto\"\n",
      "}\n",
      "[Exa Tool] Autoprompt: Here is a great restaurant in Toronto to try:\n",
      "Got output: [{'title': 'PATOIS • TORONTO', 'url': 'https://www.patoistoronto.com/', 'id': '5EC2l7fbaPoEydNVNwjc-A'}, {'title': 'Portuguese inspired seafood from around the world | Adega Restaurante', 'url': 'https://adegarestaurante.ca/', 'id': 'oQiAWWgzrU-ryPNmgj3UuA'}, {'title': 'Location', 'url': 'https://osteriagiulia.ca/', 'id': 'mpjelsyCOpNipFFI5AoZTQ'}, {'title': 'Enigma Yorkville | Modern European Restaurant in Toronto, ON', 'url': 'https://www.enigmayorkville.com/', 'id': 'jBOC2QfhTfuPjt0YdibEVA'}, {'title': 'Select A Restaurant', 'url': 'https://www.torontopho.com/', 'id': 'Hk6LQnLIZsCH8SYrNFoO2Q'}, {'title': 'Welcome to \"Woodlot Toronto\" restaurant! - Woodlot Toronto', 'url': 'https://woodlottoronto.com/', 'id': 'VUKoFW1gttmNySwHYhlgJw'}, {'title': 'Discover Opus Restaurant', 'url': 'https://www.opusrestaurant.com/#home', 'id': 'mCJBZ9lAxM2jouP0vcdbxA'}, {'title': 'Home', 'url': 'https://www.avelorestaurant.com/', 'id': 'NDfST6oMKpJ0I-VYUf_WHA'}, {'title': 'Home | Quetzal Toronto', 'url': 'https://www.quetzaltoronto.com/', 'id': 'vp3Uxb7Apiz4tE6QBz33lA'}, {'title': 'Oretta | Toronto, ON', 'url': 'https://www.oretta.to/', 'id': 'pSN1mTBx5hQ3R-aeXKrOug'}]\n",
      "========================\n",
      "\n",
      "Here are some of the best restaurants in Toronto:\n",
      "\n",
      "1. [PATOIS • TORONTO](https://www.patoistoronto.com/)\n",
      "2. [Adega Restaurante](https://adegarestaurante.ca/)\n",
      "3. [Osteria Giulia](https://osteriagiulia.ca/)\n",
      "4. [Enigma Yorkville](https://www.enigmayorkville.com/)\n",
      "5. [Toronto Pho](https://www.torontopho.com/)\n",
      "6. [Woodlot Toronto](https://woodlottoronto.com/)\n",
      "7. [Opus Restaurant](https://www.opusrestaurant.com/#home)\n",
      "8. [Alo Restaurant](https://www.alorestaurant.com/)\n",
      "9. [Quetzal Toronto](https://www.quetzaltoronto.com/)\n",
      "10. [Oretta](https://www.oretta.to/)\n",
      "\n",
      "Please note that these are just a few recommendations and there are many more amazing restaurants in Toronto to explore.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"What are the best resturants in toronto?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44035e9-27ab-47b7-abc5-cf2fe5d1482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: tell me more about Osteria Giulia\n",
      "Osteria Giulia is a restaurant located in Toronto, Ontario. It offers a unique dining experience with a focus on Italian cuisine. The restaurant is known for its warm and inviting atmosphere, making it a popular choice for both casual dining and special occasions.\n",
      "\n",
      "The menu at Osteria Giulia features a variety of traditional Italian dishes, prepared with fresh and high-quality ingredients. From homemade pasta and risotto to wood-fired pizzas and seafood, there is something to satisfy every palate. The restaurant also offers a selection of fine wines to complement the flavors of the dishes.\n",
      "\n",
      "One of the highlights of Osteria Giulia is its commitment to using locally sourced ingredients. The restaurant takes pride in supporting local farmers and suppliers, ensuring that each dish is made with the freshest and most sustainable ingredients available.\n",
      "\n",
      "In addition to its delicious food, Osteria Giulia provides excellent service, with a knowledgeable and friendly staff that is dedicated to creating a memorable dining experience for guests. The restaurant's cozy and intimate setting adds to the overall ambiance, making it a great choice for a romantic dinner or a gathering with friends and family.\n",
      "\n",
      "Whether you're looking for a classic Italian dish or a modern twist on traditional flavors, Osteria Giulia offers a culinary experience that is sure to delight. It is a must-visit destination for food lovers in Toronto who appreciate authentic Italian cuisine in a welcoming and charming setting.\n"
     ]
    }
   ],
   "source": [
    "print(agent.chat(\"tell me more about Osteria Giulia\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c7b98-0d75-4ef0-ac47-fd3bd24d3e50",
   "metadata": {},
   "source": [
    "## Avoiding Context Window Issues\n",
    "\n",
    "The above example shows the core uses of the Exa tool. We can easily retrieve a clean list of links related to a query, and then we can fetch the content of the article as a cleaned up html extract. Alternatively, the search_and_retrieve_documents tool directly returns the documents from our search result.\n",
    "\n",
    "We can see that the content of the articles is somewhat long compared to current LLM context windows, and so to allow retrieval and summary of many documents we will set up and use another tool from LlamaIndex that allows us to load text into a VectorStore, and query it for retrieval. This is where the `search_and_retrieve_documents` tool become particularly useful. The Agent can make a single query to retrieve a large number of documents, using a very small number of tokens, and then make queries to retrieve specific information from the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a017cc61-1696-4a03-8d09-a628f9049cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.tool_spec.load_and_search.base import LoadAndSearchToolSpec\n",
    "\n",
    "# The search_and_retrieve_documents tool is the third in the tool list, as seen above\n",
    "wrapped_retrieve = LoadAndSearchToolSpec.from_defaults(\n",
    "    exa_tool_list[2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b47437-8f6d-4e94-97ca-4e35f78336f2",
   "metadata": {},
   "source": [
    "Our wrapped retrieval tools separate loading and reading into separate interfaces. We use `load` to load the documents into the vector store, and `read` to query the vector store. Let's try it out again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f81bd3-a5b9-452c-93f4-91d16c4c0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exa Tool] Autoprompt: \"Check out this article on the best explanation for machine learning transformers:\n",
      "A transformer is a type of architecture used in Natural Language Processing (NLP) tasks. It is a breakthrough model that overcame the limitations of previous seq-to-seq models like RNNs in capturing long-term dependencies in text. The transformer architecture has become the foundation for various revolutionary models such as BERT, GPT, and T5, which have been widely used in NLP tasks.\n",
      "Vaswani et al. wrote the first paper on transformers.\n"
     ]
    }
   ],
   "source": [
    "wrapped_retrieve.load(\"This is the best explanation for machine learning transformers:\")\n",
    "print(wrapped_retrieve.read(\"what is a transformer\"))\n",
    "print(wrapped_retrieve.read(\"who wrote the first paper on transformers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be6977-c4e8-43a4-99be-3322d4b72b07",
   "metadata": {},
   "source": [
    "## Creating the Agent\n",
    "\n",
    "We now are ready to create an Agent that can use Metaphors services to it's full potential. We will use our wrapped read and load tools, as well as the `get_date` utility for the following agent and test it out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a893f26-dbb6-4b72-9795-702eaf749564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just pass the wrapped tools and the get_date utility\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [*wrapped_retrieve.to_tool_list(), exa_tool_list[4]],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5835d058-da9c-4d42-9d2a-941c73b88a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Can you summarize everything published in the last month regarding news on superconductors\n",
      "=== Calling Function ===\n",
      "Calling function: search_and_retrieve_documents with args: {\n",
      "  \"query\": \"news on superconductors\",\n",
      "  \"start_published_date\": \"2022-09-01\",\n",
      "  \"end_published_date\": \"2022-09-30\"\n",
      "}\n",
      "[Exa Tool] Autoprompt: Here is a recent article about superconductors:\n",
      "Got output: Content loaded! You can now search the information using read_search_and_retrieve_documents\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: read_search_and_retrieve_documents with args: {\n",
      "  \"query\": \"news on superconductors\"\n",
      "}\n",
      "Got output: The journal Nature has retracted a ground-breaking paper claiming to show the first room-temperature superconductor. The retraction was made due to concerns around the data analysis and allegations of manipulated results. Superconductors are materials that exhibit no electrical resistance and have various applications, such as NMR machines, quantum computing, and particle accelerators. Currently, all superconducting materials require very cold temperatures or extremely high pressures.\n",
      "========================\n",
      "\n",
      "In the last month, there have been developments in the field of superconductors. One notable news is the retraction of a ground-breaking paper published in the journal Nature. The paper claimed to show the discovery of the first room-temperature superconductor. However, due to concerns about data analysis and allegations of manipulated results, the paper has been retracted. Superconductors are materials that exhibit no electrical resistance and have various applications in fields such as NMR machines, quantum computing, and particle accelerators. Currently, all superconducting materials require very cold temperatures or extremely high pressures.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    agent.chat(\n",
    "        \"Can you summarize everything published in the last month regarding news on\"\n",
    "        \" superconductors\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ee91ca-6730-4fdd-8189-ac21022f34f1",
   "metadata": {},
   "source": [
    "We asked the agent to retrieve documents related to superconductors from this month. It used the `get_date` tool to determine the current month, and then applied the filters in Metaphor based on publication date when calling `search`. It then loaded the documents using `retrieve_documents` and read them using `read_retrieve_documents`.\n",
    "\n",
    "We can make another query to the vector store to read from it again, now that the articles are loaded:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
