{
    "name": "Mini TruthfulQA",
    "description": "This is a subset of the TruthfulQA benchmark. Only examples that are based off of Wikipedia pages are considered; and furthermore, Wikipedia pages that contain only one question are also dropped. The result is 152 examples for evaluating a RAG system.",
    "numberObservations": 152,
    "containsExamplesByHumans": true,
    "containsExamplesByAI": false,
    "sourceUrls": [
        "https://huggingface.co/datasets/truthful_qa"
    ],
    "baselines": [
        {
            "name": "llamaindex",
            "config": {
                "chunkSize": 1024,
                "llm": "gpt-3.5-turbo",
                "similarityTopK": 1,
                "embedModel": "text-embedding-ada-002"
            },
            "metrics": {
                "contextSimilarity": 0.000,
                "correctness": 3.865,
                "faithfulness": 0.612,
                "relevancy": 0.566
            },
            "codeUrl": "https://github.com/run-llama/llama_datasets/blob/main/baselines/mini_truthfulqa/llamaindex_baseline.py"
        }
    ]
}